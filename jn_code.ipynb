{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c850be-674f-4130-aa15-122a19c448af",
   "metadata": {},
   "source": [
    "###  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b2b6e8-a70b-4ec2-8257-215bf5d9bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53ee88-66a9-4b6d-b585-e9681b4deef4",
   "metadata": {},
   "source": [
    "###  Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a337c396-4a86-410e-9497-593699131179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading environment variables from .env file\n",
    "load_dotenv() \n",
    "groq_api_key = os.getenv('GROQ_API_KEY', 'your-default-api-key')  # Replace 'your-default-api-key' with the actual key if not using .env file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004d916-058b-41a9-9bcf-91b5aa97108a",
   "metadata": {},
   "source": [
    "### Initialize GROQ Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb0e7ec-84af-4b19-8dd6-3fc574c08a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing GROQ chat with provided API key, model name, and settings\n",
    "llm_groq = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-8b-8192\",  # Options: mixtral-8x7b-32768, llama3-70b-8192, gemma-7b-it, llama3-8b-8192\n",
    "    temperature=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9f554-6271-45b8-9c66-2c176e04a543",
   "metadata": {},
   "source": [
    "### Function to Handle File Uploads and Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68dc2be-7ebc-46b4-8996-55145468ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_file_uploads(file_paths):\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)  # Print the file path for debugging\n",
    "\n",
    "        # Read the PDF file\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            pdf_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                pdf_text += page.extract_text()\n",
    "                \n",
    "            # Split the text into chunks\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=50)\n",
    "            file_texts = text_splitter.split_text(pdf_text)\n",
    "            texts.extend(file_texts)\n",
    "\n",
    "            # Create metadata for each chunk\n",
    "            file_metadatas = [{\"source\": f\"{i}-{os.path.basename(file_path)}\"} for i in range(len(file_texts))]\n",
    "            metadatas.extend(file_metadatas)\n",
    "\n",
    "    return texts, metadatas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484dc3cc-98fa-4bc4-8af9-f56247608674",
   "metadata": {},
   "source": [
    "### Create Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65e1f37-8db1-4f59-a99a-4378f7df762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_vector_store(texts, metadatas):\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    docsearch = Chroma.from_texts(texts, embeddings, metadatas=metadatas)\n",
    "    return docsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44856e79-091f-463f-9fcf-9afc1e33cbb4",
   "metadata": {},
   "source": [
    "### Initialize Conversation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014eccb8-10ec-4271-a447-d98c8dfade36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_conversation_chain(docsearch):\n",
    "    message_history = ChatMessageHistory()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        chat_memory=message_history,\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm_groq,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=docsearch.as_retriever(),\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764d6c7-9211-4a17-bd4f-334f2556f6d8",
   "metadata": {},
   "source": [
    "### Upload Files and Process Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e637747d-8578-4ff0-8c7e-707613432bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/dhUfQAsllb.pdf\n",
      "/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/z1GMOTZvU1.pdf\n"
     ]
    }
   ],
   "source": [
    "# Manually specify file paths for the PDFs to be uploaded\n",
    "dir_path='/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/'\n",
    "file1=dir_path + 'dhUfQAsllb.pdf'\n",
    "file2=dir_path + 'z1GMOTZvU1.pdf'\n",
    "file_paths = [file1, file2]  # Replace with your file paths\n",
    "\n",
    "# Process uploaded files\n",
    "texts, metadatas = handle_file_uploads(file_paths)\n",
    "\n",
    "# Create Chroma vector store\n",
    "docsearch = create_chroma_vector_store(texts, metadatas)\n",
    "\n",
    "# Initialize conversation chain\n",
    "chain = initialize_conversation_chain(docsearch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13a821-feb0-4b1d-85da-83c182478d59",
   "metadata": {},
   "source": [
    "### Handle User Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57e5a5b-94c6-412b-827a-25dfa744d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query, chain):\n",
    "    # Call the chain with the user's query\n",
    "    res = chain(query)\n",
    "    answer = res[\"answer\"]\n",
    "    source_documents = res[\"source_documents\"] \n",
    "\n",
    "    text_elements = []  # Initialize list to store text elements\n",
    "    \n",
    "    # Process source documents if available\n",
    "    if source_documents:\n",
    "        for source_idx, source_doc in enumerate(source_documents):\n",
    "            source_name = f\"source_{source_idx}\"\n",
    "            # Create the text element referenced in the message\n",
    "            text_elements.append(source_doc.page_content)\n",
    "    \n",
    "    # Return answer and sources\n",
    "    return answer, text_elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0b1ed-5873-4958-b73a-80469ca391f2",
   "metadata": {},
   "source": [
    "### Simulate User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b05537-1688-48d8-a1b2-74a866b7b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't have enough information to answer that question. The given data only includes transactions from 15th April 2019 onwards, and there is no transaction on 12th April 2019.\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "query = \"What is the total bond amount enchased by TELUGU DESAM PARTY on 12th April 2019??\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)\n",
    "# print(\"Sources:\", sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf33c99-29fa-47f7-ac1a-ff6b8a0cfec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I apologize, but there is no record of CHOUDHARY GARMENTS in the provided data. Therefore, I cannot determine the total bond amount purchased by CHOUDHARY GARMENTS on 12th April 2019 as it does not exist in the data.\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "query = \"What is the total bond amount purchased by CHOUDHARY GARMENTS on 12th April 2019?\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3323822b-faff-416a-b324-de74075de5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I apologize, but there is no record of ACROPOLIS MAINTENANCE SERVICES PRIVATE LIMITED purchasing bonds on 12th April 2019 or any other date in the provided data. The data only shows transactions for other companies and individuals, but not for ACROPOLIS MAINTENANCE SERVICES PRIVATE LIMITED.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example user query\n",
    "query = \"What is the total number of bonds purchased by ACROPOLIS MAINTENANCE SERVICES PRIVATE LIMITED on 12th April 2019?\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51364be9-2686-4fd0-a4b7-169e6e56c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I can help you with that!\n",
      "\n",
      "After reviewing the provided data, I found the following transactions related to AAM AADMI PARTY and DR. MANDEEP SHARMA:\n",
      "\n",
      "1. 11915-11919: 6 transactions with a total amount of 6 x 1,00,00,000 = 6,00,00,000\n",
      "2. 11920-11927: 8 transactions with a total amount of 8 x 10,00,000 = 80,00,000\n",
      "3. 11579-11591: 13 transactions with a total amount of 13 x 10,00,000 = 1,30,00,000\n",
      "4. 11559-11562: 4 transactions with a total amount of 4 x 1,00,00,000 = 4,00,00,000\n",
      "5. 13164: 1 transaction with a total amount of 1,00,00,000\n",
      "\n",
      "Adding up these amounts, the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022 is:\n",
      "\n",
      "6,00,00,000 + 80,00,000 + 1,30,00,000 + 4,00,00,000 + 1,00,00,000 = 12,50,00,000\n",
      "\n",
      "So, the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022 is 12,50,00,000.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example user query\n",
    "query = \"What is the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022?\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd1b7bce-9eab-4a00-a5fc-44f1145dcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: To find the total bond amount enchased by TELUGU DESAM PARTY, I'll go through the given data and add up the bond amounts.\n",
      "\n",
      "Here are the bond amounts enchased by TELUGU DESAM PARTY:\n",
      "\n",
      "* 14622-14630: 1,00,00,000 (10,00,000 x 10)\n",
      "* 761-764: 1,00,00,000 (10,00,000 x 10)\n",
      "* 19687-19694: 1,00,00,000 (10,00,000 x 10)\n",
      "* 5562-5567: 1,00,00,000 (10,00,000 x 10)\n",
      "\n",
      "Adding up these amounts, the total bond amount enchased by TELUGU DESAM PARTY is:\n",
      "\n",
      "10,00,000 x 40 = 40,00,00,000\n",
      "\n",
      "So, the total bond amount enchased by TELUGU DESAM PARTY is 40,00,00,000.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example user query\n",
    "query = f\"\"\" Using the below information answer the given question.\n",
    "Information:\n",
    "Total bound encased by party list:\n",
    "AAP : 500K\n",
    "BJP : 1000K\n",
    "TELUGU DESAM PARTY : 50K\n",
    "\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on 12th April 2019\"\"\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a036c1-d549-4cee-ab5b-f6652d4e0cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365bfeaa-3286-4c08-bed4-d7dfd80b041b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
