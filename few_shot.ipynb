{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c850be-674f-4130-aa15-122a19c448af",
   "metadata": {},
   "source": [
    "###  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b2b6e8-a70b-4ec2-8257-215bf5d9bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53ee88-66a9-4b6d-b585-e9681b4deef4",
   "metadata": {},
   "source": [
    "###  Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a337c396-4a86-410e-9497-593699131179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading environment variables from .env file\n",
    "load_dotenv() \n",
    "groq_api_key = os.getenv('GROQ_API_KEY', 'your-default-api-key')  # Replace 'your-default-api-key' with the actual key if not using .env file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004d916-058b-41a9-9bcf-91b5aa97108a",
   "metadata": {},
   "source": [
    "### Initialize GROQ Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb0e7ec-84af-4b19-8dd6-3fc574c08a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing GROQ chat with provided API key, model name, and settings\n",
    "llm_groq = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-8b-8192\",  # Options: mixtral-8x7b-32768, llama3-70b-8192, gemma-7b-it, llama3-8b-8192\n",
    "    temperature=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9f554-6271-45b8-9c66-2c176e04a543",
   "metadata": {},
   "source": [
    "### Function to Handle File Uploads and Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68dc2be-7ebc-46b4-8996-55145468ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_file_uploads(file_paths):\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)  # Print the file path for debugging\n",
    "\n",
    "        # Read the PDF file\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            pdf_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                pdf_text += page.extract_text()\n",
    "                \n",
    "            # Split the text into chunks\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=50)\n",
    "            file_texts = text_splitter.split_text(pdf_text)\n",
    "            texts.extend(file_texts)\n",
    "\n",
    "            # Create metadata for each chunk\n",
    "            file_metadatas = [{\"source\": f\"{i}-{os.path.basename(file_path)}\"} for i in range(len(file_texts))]\n",
    "            metadatas.extend(file_metadatas)\n",
    "\n",
    "    return texts, metadatas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484dc3cc-98fa-4bc4-8af9-f56247608674",
   "metadata": {},
   "source": [
    "### Create Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65e1f37-8db1-4f59-a99a-4378f7df762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_vector_store(texts, metadatas):\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    docsearch = Chroma.from_texts(texts, embeddings, metadatas=metadatas)\n",
    "    return docsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44856e79-091f-463f-9fcf-9afc1e33cbb4",
   "metadata": {},
   "source": [
    "### Initialize Conversation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014eccb8-10ec-4271-a447-d98c8dfade36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_conversation_chain(docsearch):\n",
    "    message_history = ChatMessageHistory()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        chat_memory=message_history,\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm_groq,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=docsearch.as_retriever(),\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764d6c7-9211-4a17-bd4f-334f2556f6d8",
   "metadata": {},
   "source": [
    "### Upload Files and Process Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e637747d-8578-4ff0-8c7e-707613432bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/dhUfQAsllb.pdf\n",
      "/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/z1GMOTZvU1.pdf\n"
     ]
    }
   ],
   "source": [
    "# Manually specify file paths for the PDFs to be uploaded\n",
    "dir_path='/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/'\n",
    "file1=dir_path + 'dhUfQAsllb.pdf'\n",
    "file2=dir_path + 'z1GMOTZvU1.pdf'\n",
    "file_paths = [file1, file2]  # Replace with your file paths\n",
    "\n",
    "# Process uploaded files\n",
    "texts, metadatas = handle_file_uploads(file_paths)\n",
    "\n",
    "# Create Chroma vector store\n",
    "docsearch = create_chroma_vector_store(texts, metadatas)\n",
    "\n",
    "# Initialize conversation chain\n",
    "chain = initialize_conversation_chain(docsearch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13a821-feb0-4b1d-85da-83c182478d59",
   "metadata": {},
   "source": [
    "### Handle User Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57e5a5b-94c6-412b-827a-25dfa744d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query, chain):\n",
    "    # Call the chain with the user's query\n",
    "    res = chain(query)\n",
    "    answer = res[\"answer\"]\n",
    "    source_documents = res[\"source_documents\"] \n",
    "\n",
    "    text_elements = []  # Initialize list to store text elements\n",
    "    \n",
    "    # Process source documents if available\n",
    "    if source_documents:\n",
    "        for source_idx, source_doc in enumerate(source_documents):\n",
    "            source_name = f\"source_{source_idx}\"\n",
    "            # Create the text element referenced in the message\n",
    "            text_elements.append(source_doc.page_content)\n",
    "    \n",
    "    # Return answer and sources\n",
    "    return answer, text_elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0b1ed-5873-4958-b73a-80469ca391f2",
   "metadata": {},
   "source": [
    "### Simulate User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b05537-1688-48d8-a1b2-74a866b7b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't have enough information to answer that question. The given data only includes transactions from 15th April 2019 onwards, and there is no transaction on 12th April 2019.\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "query = \"What is the total bond amount enchased by TELUGU DESAM PARTY on 12th April 2019??\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)\n",
    "# print(\"Sources:\", sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf33c99-29fa-47f7-ac1a-ff6b8a0cfec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I apologize, but there is no record of CHOUDHARY GARMENTS in the provided data. Therefore, I cannot determine the total bond amount purchased by CHOUDHARY GARMENTS on 12th April 2019 as it does not exist in the data.\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "query = \"What is the total bond amount purchased by CHOUDHARY GARMENTS on 12th April 2019?\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3323822b-faff-416a-b324-de74075de5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I apologize, but there is no record of ACROPOLIS MAINTENANCE SERVICES PRIVATE LIMITED purchasing bonds on 12th April 2019 or any other date in the provided data. The data only shows transactions for other companies and individuals, but not for ACROPOLIS MAINTENANCE SERVICES PRIVATE LIMITED.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example user query\n",
    "query = \"What is the total number of bonds purchased by ACROPOLIS MAINTENANCE SERVICES PRIVATE LIMITED on 12th April 2019?\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51364be9-2686-4fd0-a4b7-169e6e56c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I can help you with that!\n",
      "\n",
      "After reviewing the provided data, I found the following transactions related to AAM AADMI PARTY and DR. MANDEEP SHARMA:\n",
      "\n",
      "1. 11915-11919: 6 transactions with a total amount of 6 x 1,00,00,000 = 6,00,00,000\n",
      "2. 11920-11927: 8 transactions with a total amount of 8 x 10,00,000 = 80,00,000\n",
      "3. 11579-11591: 13 transactions with a total amount of 13 x 10,00,000 = 1,30,00,000\n",
      "4. 11559-11562: 4 transactions with a total amount of 4 x 1,00,00,000 = 4,00,00,000\n",
      "5. 13164: 1 transaction with a total amount of 1,00,00,000\n",
      "\n",
      "Adding up these amounts, the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022 is:\n",
      "\n",
      "6,00,00,000 + 80,00,000 + 1,30,00,000 + 4,00,00,000 + 1,00,00,000 = 12,50,00,000\n",
      "\n",
      "So, the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022 is 12,50,00,000.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example user query\n",
    "query = \"What is the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022?\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "311b34ec-1c7b-4cda-9050-eba7cd90db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "    return full_text\n",
    "\n",
    "def generate_few_shot_prompt(pdf_text):\n",
    "    prompt = f\"\"\"\n",
    "I have a PDF document containing details about the encashments of bonds by political parties. I need to extract specific information from this PDF. Here are some examples of the information I need:\n",
    "\n",
    "### Example 1:\n",
    "PDF Text:\n",
    "\"Date of Encashment: 2023-06-15\n",
    "Name of the Political Party: Party A\n",
    "Account Number: 123456789\n",
    "Bond Number: ABC123\n",
    "Denominations: 1000\n",
    "Pay Branch Code: 001\n",
    "Pay Teller: John Doe\"\n",
    "\n",
    "Extracted Information:\n",
    "- Date of Encashment: 2023-06-15\n",
    "- Name of the Political Party: Party A\n",
    "- Account Number: 123456789\n",
    "- Bond Number: ABC123\n",
    "- Denominations: 1000\n",
    "\n",
    "\n",
    "### Example 2:\n",
    "PDF Text:\n",
    "\"Date of Encashment: 2023-07-01\n",
    "Name of the Political Party: Party B\n",
    "Account Number: 987654321\n",
    "Bond Number: XYZ456\n",
    "Denominations: 5000\n",
    "\n",
    "Extracted Information:\n",
    "- Date of Encashment: 2023-07-01\n",
    "- Name of the Political Party: Party B\n",
    "- Account Number: 987654321\n",
    "- Bond Number: XYZ456\n",
    "- Denominations: 5000\n",
    "\n",
    "\n",
    "### Task:\n",
    "Given the text from the PDF, extract the details in the same format as the examples above.\n",
    "\n",
    "PDF Text:\n",
    "\"{pdf_text}\"\n",
    "\n",
    "Extracted Information:\n",
    "- Date of Encashment:\n",
    "- Name of the Political Party:\n",
    "- Account Number:\n",
    "- Bond Number:\n",
    "- Denominations:\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\n",
    "\"\"\"\n",
    "    return prompt\n",
    "# Example usage\n",
    "pdf_path = '/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/dhUfQAsllb.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "few_shot_prompt = generate_few_shot_prompt(pdf_text)\n",
    "# print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86445ec-2da4-45ff-8b3b-467d24fa6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        full_text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc93e69f-fd9f-4988-b7a6-0fde5b295d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_few_shot_prompt(pdf_text):\n",
    "    prompt = f\"\"\"\n",
    "I have a PDF document containing details about the encashments of bonds by political parties. Answer the Question using examples provided:\n",
    "\n",
    "### Example 1:\n",
    "PDF Text:\n",
    "\"Date of Encashment: 2023-06-15\n",
    "Name of the Political Party: Party A\n",
    "Account Number: 123456789\n",
    "Bond Number: ABC123\n",
    "Denominations: 1000\n",
    "Pay Branch Code: 001\n",
    "Pay Teller: John Doe\"\n",
    "\n",
    "\n",
    "### Example 2:\n",
    "PDF Text:\n",
    "\"Date of Encashment: 2023-07-01\n",
    "Name of the Political Party: Party B\n",
    "Account Number: 987654321\n",
    "Bond Number: XYZ456\n",
    "Denominations: 5000\n",
    "\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\n",
    "\"\"\"\n",
    "    return prompt\n",
    "# Example usage\n",
    "pdf_path = '/home/phdcs2/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/file/dhUfQAsllb.pdf'\n",
    "# pdf_text = extract_text_from_pdf(pdf_path)\n",
    "few_shot_prompt = generate_few_shot_prompt(pdf_text)\n",
    "# print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "83b696d3-41a8-49a1-bb82-224ae4d0b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided data, the total bond amount enchased by TELUGU DESAM PARTY on April 2019 is:\n",
      "\n",
      "750: 1,00,00,000\n",
      "751: 10,00,000\n",
      "752: 10,00,000\n",
      "753: 10,00,000\n",
      "754: 10,00,000\n",
      "755: 10,00,000\n",
      "756: 10,00,000\n",
      "757: 10,00,000\n",
      "758: 10,00,000\n",
      "759: 10,00,000\n",
      "760: 10,00,000\n",
      "\n",
      "Total bond amount enchased by TELUGU DESAM PARTY on April 2019 is: 1,00,00,000 + 10,00,000 x 10 = 1,10,00,000\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\" \"{few_shot_prompt}\"\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\"\"\"\n",
    "\n",
    "# Handle the query`\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd71ece3-20c1-4eb2-9386-ac43b2423ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Please reduce the length of the messages or completion.', 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfew_shot_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mQuestion:\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mWhat is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Handle the query`\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m answer, sources \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, answer)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mhandle_query\u001b[0;34m(query, chain)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_query\u001b[39m(query, chain):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Call the chain with the user's query\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     answer \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     source_documents \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     emit_warning()\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    381\u001b[0m }\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/conversational_retrieval/base.py:147\u001b[0m, in \u001b[0;36mBaseConversationalRetrievalChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_history_str:\n\u001b[1;32m    146\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m _run_manager\u001b[38;5;241m.\u001b[39mget_child()\n\u001b[0;32m--> 147\u001b[0m     new_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_history_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     new_question \u001b[38;5;241m=\u001b[39m question\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     emit_warning()\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:605\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    601\u001b[0m         _output_key\n\u001b[1;32m    602\u001b[0m     ]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    606\u001b[0m         _output_key\n\u001b[1;32m    607\u001b[0m     ]\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     emit_warning()\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    381\u001b[0m }\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    124\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain/chains/llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    147\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    148\u001b[0m     )\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:677\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    671\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    675\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    676\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:534\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    533\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 534\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    535\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    536\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    538\u001b[0m ]\n\u001b[1;32m    539\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:524\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 524\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m         )\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:749\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 749\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/langchain_groq/chat_models.py:472\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    468\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    471\u001b[0m }\n\u001b[0;32m--> 472\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/groq/resources/chat/completions.py:289\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/groq/_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1224\u001b[0m     )\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/groq/_base_client.py:920\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    919\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hard_Disk/Projects/chatgpt/Multi-PDF-llama3Chat/venv/lib/python3.8/site-packages/groq/_base_client.py:1018\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1017\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1021\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1022\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1026\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Please reduce the length of the messages or completion.', 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
     ]
    }
   ],
   "source": [
    "query = f\"\"\" \"{few_shot_prompt}\"\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\"\"\"\n",
    "\n",
    "# Handle the query`\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ebf2f-9798-4e0a-9d7b-d235312ac6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Issue Branch Code, Pay Teller, Issue Teller, Account Number of Political Party.\n",
    "# Example user query\n",
    "query = f\"\"\"Using the below information answer the given question.\n",
    "Information:\n",
    "Total bonds encased by party list:\n",
    "AAP : 500K\n",
    "BJP : 1000K\n",
    "TELUGU DESAM PARTY : 50K\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\"\"\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbcc8b-097c-4edd-bd2c-003273e884f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c98fd49-39a3-4a04-a2a8-c55ecb1dff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b320dba6-32f8-491d-9d62-95afc119ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FewShotPrompt(test_entry, exemplars):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Read the math problem and write the answer.\"}]\n",
    "    for entry in exemplars:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"[question] \" + entry['question']})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"[answer] \" + entry['numerical_answer']})\n",
    "    messages.append({\"role\": \"user\", \"content\": \"[question] \" + test_entry['question']})\n",
    "\n",
    "    # messages = [{\"role\": \"system\", \"content\": \"MATH PROBLEM INSTRUCTIONS\"}]\n",
    "    # for entry in exemplars:\n",
    "    #     messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
    "    #     messages.append({\"role\": \"assistant\", \"content\": \"ANSWER HERE\"})\n",
    "    # messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a88f9627-6ab4-4e3e-81cc-b97a2407a5df",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m message\u001b[38;5;241m=\u001b[39m\u001b[43mFewShotPrompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfew_shot_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m, in \u001b[0;36mFewShotPrompt\u001b[0;34m(test_entry, exemplars)\u001b[0m\n\u001b[1;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead the math problem and write the answer.\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m exemplars:\n\u001b[0;32m----> 4\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[question] \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m})\n\u001b[1;32m      5\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[answer] \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m      6\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[question] \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m test_entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "message=FewShotPrompt(query, few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572498e-380a-41b9-a587-298d3ecff6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for entry in tqdm(test_dataset):\n",
    "    messages = few_shot_prompt(entry, exemplars)\n",
    "    ret = run_groq_model(messages, \"llama3-8b-8192\", max_tokens=16, temperature=0.0)\n",
    "    results.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd1b7bce-9eab-4a00-a5fc-44f1145dcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided data, the total bond amount enchased by TELUGU DESAM PARTY on April 2019 is:\n",
      "\n",
      "* 6666 (from record 750)\n",
      "* 12957 (from record 751)\n",
      "* 12965 (from record 752)\n",
      "* 12848 (from record 753)\n",
      "* 12967 (from record 754)\n",
      "* 12955 (from record 755)\n",
      "* 12850 (from record 756)\n",
      "* 12959 (from record 757)\n",
      "* 12963 (from record 758)\n",
      "* 12961 (from record 759)\n",
      "* 12969 (from record 760)\n",
      "\n",
      "The total bond amount is:\n",
      "6666 + 12957 + 12965 + 12848 + 12967 + 12955 + 12850 + 12959 + 12963 + 12961 + 12969 = 1,00,00,000\n",
      "\n",
      "So, the total bond amount enchased by TELUGU DESAM PARTY on April 2019 is 1,00,00,000.\n"
     ]
    }
   ],
   "source": [
    "# Ignore Issue Branch Code, Pay Teller, Issue Teller, Account Number of Political Party.\n",
    "# Example user query\n",
    "query = f\"\"\"Using the below information answer the given question.\n",
    "Information:\n",
    "Total bonds encased by party list:\n",
    "AAP : 500K\n",
    "BJP : 1000K\n",
    "TELUGU DESAM PARTY : 50K\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on April 2019?\"\"\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42609a7d-519f-4e0e-918f-3364f30d0e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I can help you with that!\n",
      "\n",
      "According to the given data, the TELUGU DESAM PARTY has the following bond amounts enchased between 17 to 20 April 2019:\n",
      "\n",
      "* 14622: 1,00,00,000\n",
      "* 14623: 1,00,00,000\n",
      "* 14624: 1,00,00,000\n",
      "* 14625: 1,00,00,000\n",
      "* 14626: 1,00,00,000\n",
      "* 14627: 1,00,00,000\n",
      "* 14628: 1,00,00,000\n",
      "* 14629: 1,00,00,000\n",
      "* 14630: 1,00,00,000\n",
      "* 14631: 1,00,00,000\n",
      "* 14632: 1,00,00,000\n",
      "* 14633: 1,00,00,000\n",
      "* 14634: 1,00,00,000\n",
      "* 14635: 1,00,00,000\n",
      "\n",
      "The total bond amount enchased by TELUGU DESAM PARTY between 17 to 20 April 2019 is:\n",
      "\n",
      "1,00,00,000 + 1,00,00,000 + ... + 1,00,00,000 = 14,00,00,000\n",
      "\n",
      "So, the total bond amount enchased by TELUGU DESAM PARTY between 17 to 20 April 2019 is 14,00,00,000.\n"
     ]
    }
   ],
   "source": [
    "# Ignore Issue Branch Code, Pay Teller, Issue Teller, Account Number of Political Party.\n",
    "# Example user query\n",
    "query = f\"\"\" Using the below Information answer the given Question .\n",
    "Information:\n",
    "Denominations by party list enchased on a specific date.\n",
    "Total bound encased by party list:\n",
    "SHIVSENA : select denominations from file \n",
    "BHARATIYA JANATA PARTY : select denominations from file\n",
    "ALL INDIA TRINAMOOL CONGRESS : select denominations from file\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY between 17 to 20 April 2019\"\"\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28743618-2a0c-4bf0-a0b1-10d2fe905fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't have enough information to answer that question. The provided data only includes transactions from 15th April 2019 onwards, and there is no record of a transaction on 12th April 2019.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\" Using the below Information answer the given Question .\n",
    "Information:\n",
    "on 12/Apr/2019 Bhartiya Janta Party enchased total money : Sum of all Denominations on the 12/Apr/2019 for Bhartiya Janta PARTY \n",
    "on 16/Dec/2022 YSR CONGRESS PARTY enchased total money : Sum of all Denominations on the 12/Dec/2022 for YSR CONGRESS PARTY\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on 12th April 2019??\"\"\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "224c4a51-4f2c-4629-a573-a34555bb28be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't have enough information to answer that question. The provided data only includes transactions from 15th April 2019 onwards, and there is no record of a transaction on 12th April 2019.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\" Using the below Information answer the given Question .\n",
    "Information:\n",
    "Q1: total bond amount enchased by ALL INDIA ANNA DRAVIDA MUNNETRA KAZHAGAM on 12th April 2019?\n",
    "\n",
    "R1: make sum of all Denominations on the given date for ALL INDIA ANNA DRAVIDA MUNNETRA KAZHAGAM\n",
    "\n",
    "30*10,00,000 + 3 * 1,00,00,000 = 6,00,00,000\n",
    "\n",
    "Q2: total bond amount enchased by BHARATIYA JANATA PARTY on 12th April 2019?\n",
    "\n",
    "R2: make sum of all Denominations on the given date for BHARATIYA JANATA PARTY\n",
    "\n",
    "402 * denominations\n",
    "\n",
    "Q3: total bond amount enchased by BHARAT RASHTRA SAMITHI on 12th April 2019?\n",
    "\n",
    "R3: make sum of all Denominations on the given date for BHARAT RASHTRA SAMITHI\n",
    "\n",
    "26 * Denominations\n",
    "\n",
    "Question:\n",
    "What is the total bond amount enchased by TELUGU DESAM PARTY on 12th April 2019??\"\"\"\n",
    "\n",
    "# Handle the query\n",
    "answer, sources = handle_query(query, chain)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32858688-3dba-416e-b5c5-6189b743ebf2",
   "metadata": {},
   "source": [
    "### Get The final Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31a036c1-d549-4cee-ab5b-f6652d4e0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def get_final_answer(entry):\n",
    "    entry['numerical_answer'] = entry['answer'].split('\\n')[-1].split(' ', 1)[-1].strip()\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54962f61-3a48-40a0-80cf-f018c71d2d70",
   "metadata": {},
   "source": [
    "### Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a463debe-b0af-4a30-ae69-1a585eefdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(golds, preds):\n",
    "    cnt = 0\n",
    "    for gg, pp in zip(golds, preds):\n",
    "        gg = float(gg.replace(',', ''))\n",
    "        try:\n",
    "            pp = float(pp.replace(',', ''))\n",
    "        except:\n",
    "            pp = None\n",
    "\n",
    "        if gg == pp:\n",
    "            cnt += 1\n",
    "    return cnt / len(golds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f402b9-ac93-473c-9d9d-70844fa27a38",
   "metadata": {},
   "source": [
    "## Few Shot Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd5dcd-897c-45d7-a901-3d8e88f1d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplars={'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
    " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
    " 'numerical_answer': '72',\n",
    " 'code': 'Here is the step-by-step Python code for the given problem.\\n```# Clips sold in April\\nclips_april = 48\\n\\n# Clips sold in May (half of April)\\nclips_may = clips_april / 2\\n\\n# Total clips sold\\ntotal_clips = clips_april + clips_may\\nprint(\"FINAL ANSWER:\", total_clips)\\n```\\nThe final answer is \"total_clip\" '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f722a5-e70b-40e0-b66b-a83b92042bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prompt(test_entry, exemplars):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"MATH PROBLEM INSTRUCTIONS\"}]\n",
    "    for entry in exemplars:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"ANSWER HERE\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803794f-8e22-470e-ad27-1a7a2f8d1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prompt(test_entry, exemplars):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Read the Question and write the answer.\"}]\n",
    "    for entry in exemplars:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"[question] \" + entry['question']})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"[answer] \" + entry['numerical_answer']})\n",
    "    messages.append({\"role\": \"user\", \"content\": \"[question] \" + test_entry['question']})\n",
    "\n",
    "    # messages = [{\"role\": \"system\", \"content\": \"MATH PROBLEM INSTRUCTIONS\"}]\n",
    "    # for entry in exemplars:\n",
    "    #     messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
    "    #     messages.append({\"role\": \"assistant\", \"content\": \"ANSWER HERE\"})\n",
    "    # messages.append({\"role\": \"user\", \"content\": \"QUESTION HERE\"})\n",
    "\n",
    "    return messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
